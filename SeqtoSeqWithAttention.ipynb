{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11817792,"sourceType":"datasetVersion","datasetId":7422871},{"sourceId":11867325,"sourceType":"datasetVersion","datasetId":7457466},{"sourceId":11868230,"sourceType":"datasetVersion","datasetId":7458108},{"sourceId":11875952,"sourceType":"datasetVersion","datasetId":7463670}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import Lib\n\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.autograd import Variable \nimport copy\nfrom matplotlib.font_manager import FontProperties\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader, TensorDataset\nimport random\nimport heapq\nimport wandb\nimport matplotlib.pyplot as plt\n# Set device (CUDA if available)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:11:19.464008Z","iopub.execute_input":"2025-05-20T13:11:19.464336Z","iopub.status.idle":"2025-05-20T13:11:26.338031Z","shell.execute_reply.started":"2025-05-20T13:11:19.464315Z","shell.execute_reply":"2025-05-20T13:11:26.337341Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"wandb.login(key='b8d44a4abbab8753e976a6e5ab717fd669ba99a2')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T13:11:29.813422Z","iopub.execute_input":"2025-05-20T13:11:29.814280Z","iopub.status.idle":"2025-05-20T13:11:36.290613Z","shell.execute_reply.started":"2025-05-20T13:11:29.814245Z","shell.execute_reply":"2025-05-20T13:11:36.289853Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs24m030\u001b[0m (\u001b[33mcs24m030-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"## PREPROCESSING","metadata":{}},{"cell_type":"code","source":"def encode(x, max_length, char_to_idx):\n    encoded = np.zeros(max_length, dtype=int)\n    encoder = np.array([char_to_idx[char] for char in x])\n    length = min(max_length, len(encoder))\n    encoded[:length] = encoder[:length]\n\n    return torch.tensor(encoded, dtype=torch.int64), length\n\ndef get_tensor_object(df, max_input_length, max_output_length, char_to_idx_input, char_to_idx_output):\n    # Encode unique inputs and outputs into tensors\n    encoded_inputs = []\n    encoded_outputs = []\n\n    # Encode the input column\n    for input_str in df[0]:\n        encoded_input, input_length = encode(input_str, max_input_length, char_to_idx_input)\n        encoded_inputs.append(encoded_input)\n\n    # Encode the output column\n    for output_str in df[1]:\n        encoded_output, output_length = encode(output_str, max_output_length, char_to_idx_output)\n        encoded_outputs.append(encoded_output)\n\n    # Stack tensors column-wise\n    \n#     tensor_inputs = torch.stack(encoded_inputs, dim=1)\n#     tensor_outputs = torch.stack(encoded_outputs, dim=1)\n    tensor_inputs = torch.stack(encoded_inputs)\n    tensor_outputs = torch.stack(encoded_outputs)\n\n    return tensor_inputs, tensor_outputs\n\ndef load_dataset(path):\n    \"\"\"\n    Load a dataset from a TSV file.\n    Args:\n    - path (str): Path to the TSV file.\n    Returns:\n    - df (pd.DataFrame): Loaded DataFrame.\n    - max_input_length (int): Maximum length for input sequences.\n    - max_output_length (int): Maximum length for output sequences.\n    \"\"\"\n    df = pd.read_csv(path, header=None, encoding='utf-8', sep='\\t')  # Changed separator to tab\n    \n    # Convert values to strings before adding special characters\n    df[0] = df[0].astype(str).apply(lambda x: x + '$')\n    df[1] = df[1].astype(str).apply(lambda x: '^' + x + '$')\n    \n    # Determine maximum length for input and output sequences\n    max_input_length = max(len(x) for x in df[0].unique())\n    max_output_length = max(len(x) for x in df[1].unique())\n    return df, max_input_length, max_output_length\n\ndef look_up_table(vocab1, vocab2, vocab3):\n    # Combine all vocabularies into one set\n    vocab = set(''.join(vocab1) + ''.join(vocab2) + ''.join(vocab3))\n    vocab.discard('^')  \n    vocab.discard('$')  \n    vocab_to_int = {\"\": 0, '^':1, '$':2}\n    for v_i, v in enumerate(sorted(vocab), len(vocab_to_int)):\n        vocab_to_int[v] = v_i\n    int_to_vocab = {v_i: v for v, v_i in vocab_to_int.items()}\n    return vocab_to_int, int_to_vocab\n\n\n\n\n# Load Dataset\ndf_train, train_input_len, train_out_len = load_dataset('/kaggle/input/dakshina/hi.translit.sampled.train.tsv')\ndf_val, val_input_len, val_out_len = load_dataset('/kaggle/input/dakshina/hi.translit.sampled.dev.tsv')\ndf_test, test_input_len, test_out_len = load_dataset('/kaggle/input/dakshina/hi.translit.sampled.test.tsv')\n\ninput_max_len = max(train_input_len, val_input_len, test_input_len) + 1\noutput_max_len = max(train_out_len, val_out_len, test_out_len) + 1\n\n\n# Create Look Up Table\ninput_char_to_int, input_int_to_char = look_up_table(df_train[0], df_val[0], df_test[0])\noutput_char_to_int, output_int_to_char = look_up_table(df_train[1], df_val[1], df_test[1])\n\nprint(\"Input Lookup Table:\", input_char_to_int)\nprint(\"\\n\\n Output Lookup Table\", output_char_to_int)\n\n# Data Embedding and Converting them into Tensor\ntrain_inputs, train_outputs = get_tensor_object(df_train, input_max_len, input_max_len, input_char_to_int, output_char_to_int)\nval_inputs, val_outputs = get_tensor_object(df_val, input_max_len, input_max_len, input_char_to_int, output_char_to_int)\ntest_inputs, test_outputs = get_tensor_object(df_test, input_max_len, input_max_len, input_char_to_int, output_char_to_int)\n\n# Transpose column wise\ntrain_inputs, train_outputs = torch.transpose(train_inputs, 0, 1), torch.transpose(train_outputs, 0, 1)\nval_inputs, val_outputs = torch.transpose(val_inputs, 0, 1), torch.transpose(val_outputs, 0, 1)\ntest_inputs, test_outputs = torch.transpose(test_inputs, 0, 1), torch.transpose(test_outputs, 0, 1)\n\n\nprint(\"\\n\", train_inputs[:,0],train_outputs[:,0])\nprint(\"Training Input:\", train_inputs.shape, train_outputs.shape)\n\nprint(\"Validation\", val_inputs.shape, val_inputs.shape)\nprint(df_train.head())","metadata":{"execution":{"iopub.status.busy":"2025-05-20T13:11:39.648653Z","iopub.execute_input":"2025-05-20T13:11:39.649340Z","iopub.status.idle":"2025-05-20T13:11:41.471823Z","shell.execute_reply.started":"2025-05-20T13:11:39.649314Z","shell.execute_reply":"2025-05-20T13:11:41.471029Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Input Lookup Table: {'': 0, '^': 1, '$': 2, 'ँ': 3, 'ं': 4, 'ः': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ए': 13, 'ऐ': 14, 'ऑ': 15, 'ओ': 16, 'औ': 17, 'क': 18, 'ख': 19, 'ग': 20, 'घ': 21, 'ङ': 22, 'च': 23, 'छ': 24, 'ज': 25, 'झ': 26, 'ञ': 27, 'ट': 28, 'ठ': 29, 'ड': 30, 'ढ': 31, 'ण': 32, 'त': 33, 'थ': 34, 'द': 35, 'ध': 36, 'न': 37, 'प': 38, 'फ': 39, 'ब': 40, 'भ': 41, 'म': 42, 'य': 43, 'र': 44, 'ल': 45, 'व': 46, 'श': 47, 'ष': 48, 'स': 49, 'ह': 50, '़': 51, 'ा': 52, 'ि': 53, 'ी': 54, 'ु': 55, 'ू': 56, 'ृ': 57, 'ॅ': 58, 'े': 59, 'ै': 60, 'ॉ': 61, 'ो': 62, 'ौ': 63, '्': 64, 'ॐ': 65}\n\n\n Output Lookup Table {'': 0, '^': 1, '$': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n\n tensor([6, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([ 1,  3, 16,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0])\nTraining Input: torch.Size([21, 44204]) torch.Size([21, 44204])\nValidation torch.Size([21, 4358]) torch.Size([21, 4358])\n          0           1  2\n0       अं$        ^an$  3\n1  अंकगणित$  ^ankganit$  3\n2     अंकल$     ^uncle$  4\n3    अंकुर$     ^ankur$  4\n4   अंकुरण$   ^ankuran$  3\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Create Seq2Seq CLass","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module): \n    def __init__(self, input_size, embedding_size, hidden_size, num_layers, dropout, bidirectional, cell_type):\n        super(Encoder, self).__init__()\n        self.bidirectional = bidirectional\n        self.dropout = nn.Dropout(dropout)\n        self.num_layers = num_layers\n        self.hidden_size = hidden_size\n        self.cell_type = cell_type\n        \n        # Define embedding layer\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        \n        # Define RNN layer with specific cell type\n        if cell_type == 'LSTM':\n            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout, bidirectional=bidirectional)\n        elif cell_type == 'GRU':\n            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers, dropout=dropout, bidirectional=bidirectional)\n        elif cell_type == 'RNN':\n            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout=dropout, bidirectional=bidirectional)\n        else:\n            raise ValueError(\"Invalid RNN type. Choose from 'LSTM', 'GRU', or 'RNN'.\")\n        \n        \n    def forward(self, x): # x shape: (seq_length, N) where N is batch size\n        # Perform dropout on the input\n        embedding = self.embedding(x)\n        embedding = self.dropout(embedding) # embedding shape: (seq_length, N, embedding_size)\n        \n        if self.cell_type == \"LSTM\":\n            # Pass through the LSTM layer\n            outputs, (hidden, cell) = self.rnn(embedding) # outputs shape: (seq_length, N, hidden_size)\n            if self.bidirectional:\n                # Sum the bidirectional outputs\n                outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n                hidden = torch.cat((hidden[: self.num_layers], hidden[self.num_layers:]), dim=0)\n\n            # Return hidden state and cell state\n            return outputs, hidden, cell\n        elif self.cell_type == \"GRU\" or self.cell_type == \"RNN\":\n            # Pass through the RNN/GRU layer\n            outputs, hidden = self.rnn(embedding) # outputs shape: (seq_length, N, hidden_size)\n            if self.bidirectional:\n                # Sum the bidirectional outputs\n                outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n                hidden = torch.cat((hidden[: self.num_layers], hidden[self.num_layers:]), dim=0)\n\n            # Return output (max_seq, N, hidden size)\n            return outputs, hidden \n        else:\n            print(\"Encoder Failed to initialize!\")\n            return None\n\nclass Attention(nn.Module):\n    def __init__(self, hidden_size):\n        super(Attention, self).__init__()\n        self.hidden_size = hidden_size\n      \n    def dot_score(self, hidden_state, encoder_states):\n        return torch.sum(hidden_state * encoder_states, dim=2)\n    \n    def forward(self, hidden, encoder_outputs):\n        attn_scores = self.dot_score(hidden, encoder_outputs)\n        attn_scores = attn_scores.t()  # Transpose to match dimensions\n        attention_weights = F.softmax(attn_scores, dim=1).unsqueeze(1)\n        return attention_weights\n\nclass Decoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, dropout, bidirection_type, cell_type):\n        super(Decoder, self).__init__()\n        self.bidirectional = bidirection_type\n        self.dropout = nn.Dropout(dropout)  \n        self.num_layers = num_layers \n        self.hidden_size = hidden_size\n        self.embedding_size = embedding_size\n        self.cell_type = cell_type\n        \n        \n        # Define embedding layer\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        \n        # Define RNN layer with specific cell type\n        if cell_type == 'LSTM':\n            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=dropout)\n        elif cell_type == 'GRU':\n            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers, dropout=dropout)\n        elif cell_type == 'RNN':\n            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout=dropout)\n        else:\n            raise ValueError(\"Invalid RNN type. Choose from 'LSTM', 'GRU', or 'RNN'.\")\n        \n        \n            \n        # Define fully connected layer\n        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n        self.fc = nn.Linear(hidden_size, output_size)  \n        \n        # Attention Class object\n        self.attn = Attention(hidden_size)\n        \n        # Softmax layer\n        self.log_softmax = nn.LogSoftmax(dim=1)\n    \n    def forward(self, x, encoder_outputs, hidden, cell): # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n        \n        \n        # Ensure x has the shape (1, N)\n        x = x.unsqueeze(0)\n        \n        # Perform dropout on the input\n        embedding = self.embedding(x)\n        embedding = self.dropout(embedding)  # embedding shape: (1, N, embedding_size)\n        \n        if self.cell_type == \"LSTM\":\n            # Pass through the LSTM layer\n            outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))  # outputs shape: (1, N, hidden_size * num_directions)\n            \n            # Calculate attention weights\n            attention_weights = self.attn(outputs, encoder_outputs)\n            context = attention_weights.bmm(encoder_outputs.transpose(0, 1))\n            \n            # Concatenate  context vector and GRU output\n            outputs = outputs.squeeze(0)\n            context = context.squeeze(1)\n            concat_input = torch.cat((outputs, context), 1)\n            concat_output = torch.tanh(self.concat(concat_input))\n            \n            # Pass through fully connected layer\n            out = self.fc(concat_output)\n            predictions = self.log_softmax(out)\n\n            return predictions, hidden, cell, attention_weights.squeeze(1)\n        \n        elif self.cell_type == \"GRU\" or self.cell_type == \"RNN\":\n            # Pass through the  layer\n            outputs, hidden = self.rnn(embedding, hidden)  # outputs shape: (1, N, hidden_size * num_directions)\n            \n            # Calculate attention weights\n            attention_weights = self.attn(outputs, encoder_outputs)\n            context = attention_weights.bmm(encoder_outputs.transpose(0, 1))\n            \n            # Concatenate  context vector and GRU output\n            outputs = outputs.squeeze(0)\n            context = context.squeeze(1)\n            concat_input = torch.cat((outputs, context), 1)\n            concat_output = torch.tanh(self.concat(concat_input))\n\n            \n            # Pass through fully connected layer\n            out = self.fc(concat_output)\n            predictions = self.log_softmax(out)\n            \n            return predictions, hidden, attention_weights.squeeze(1)\n    \n        else:\n            print(\"Encoder Failed to initialized!!!!!!!!\")\n            return None\n        \nclass Seq2Seq(nn.Module):\n\n    def __init__(self, encoder, decoder, output_char_to_int, teacher_forcing, cell_type):\n\n        super(Seq2Seq, self).__init__()  \n        # Initialize encoder and decoder\n        self.decoder = decoder\n        self.encoder = encoder\n        self.cell_type = cell_type\n        self.target_vocab_size =  len(output_char_to_int)\n        self.teacher_force_ratio = teacher_forcing\n    \n#     def create_mask(self, input_sequence):\n#         return (input_sequence != 0).permute(1, 0)\n    \n    def forward(self, source, target):\n        \n        # Get batch size, target length, and target vocabulary size\n        batch_size = source.shape[1]\n        target_len = target.shape[0]\n        target_vocab_size = self.target_vocab_size\n        teacher_force_ratio = self.teacher_force_ratio\n        \n        # Initialize outputs tensor\n        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n        # Grab the first input to the Decoder which will be <SOS> token i.e '^'\n        x = target[0,:]\n        \n        # Get hidden state and cell state from encoder\n        if self.cell_type == 'LSTM':\n            encoder_outputs, hidden, cell = self.encoder(source)\n            hidden =  hidden[:self.decoder.num_layers]\n            cell =  cell[:self.decoder.num_layers]\n        else:\n            encoder_outputs, hidden = self.encoder(source)\n            hidden =  hidden[:self.decoder.num_layers]\n        \n        for t in range(1, target_len):\n            # Use previous hidden and cell states as context from encoder at start\n            if self.cell_type == 'LSTM':\n                output, hidden, cell, _ = self.decoder(x, encoder_outputs, hidden, cell)\n            else:\n                output, hidden, _ = self.decoder(x, encoder_outputs, hidden, None)\n            #output, hidden, cell = self.decoder(x, hidden, cell)\n                \n            # Store next output prediction\n            outputs[t], best_guess = output, output.argmax(1)\n            # Get the best word the Decoder predicted (index in the vocabulary)\n            x = best_guess if random.random() >= teacher_force_ratio else target[t]\n\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2025-05-20T13:11:44.934262Z","iopub.execute_input":"2025-05-20T13:11:44.934774Z","iopub.status.idle":"2025-05-20T13:11:44.953716Z","shell.execute_reply.started":"2025-05-20T13:11:44.934751Z","shell.execute_reply":"2025-05-20T13:11:44.952953Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## TRAINING","metadata":{}},{"cell_type":"code","source":"# BEAM SEARCH FUNCTION\ndef beam_search(model, input_seq, max_length, input_char_index, output_char_index, reverse_target_char_index, beam_width, length_penalty, cell_type):\n    if len(input_seq) > max_length:\n        print(\"Input Length is exceeding max length!!!!\")\n        return \"\"\n    \n    # Create np array of zero of length i/p \n    input_data = np.zeros((max_length, 1), dtype=int) # (N,1)\n    \n    # Encode the input\n    for idx, char in enumerate(input_seq):\n        input_data[idx, 0] = input_char_index[char]\n    input_data[idx+1, 0] = input_char_index[\"$\"] # EOS\n    \n    # Convert to tensor\n    input_tensor = torch.tensor(input_data, dtype=torch.int64).to(device) # N,1\n    \n    with torch.no_grad():\n        if cell_type == 'LSTM':\n            encoder_outputs, hidden, cell = model.encoder(input_tensor)\n            hidden =  hidden[:model.decoder.num_layers]\n            cell =  cell[:model.decoder.num_layers]\n        else:\n            encoder_outputs, hidden = model.encoder(input_tensor)\n            hidden =  hidden[:model.decoder.num_layers]\n    \n    # Initialize beam\n    out_t = output_char_index['^']\n    out_reshape = np.array(out_t).reshape(1,)\n    hidden_par = hidden.unsqueeze(0)\n    initial_sequence = torch.tensor(out_reshape).to(device)\n    beam = [(0.0, initial_sequence, hidden_par)]  # [(score, sequence, hidden)]\n\n    for _ in range(len(output_char_index)):\n        candidates = []\n        for score, seq, hidden in beam:\n            if seq[-1].item() == output_char_index['$']:\n                # If the sequence ends with the end token, add it to the candidates\n                candidates.append((score, seq, hidden))\n                continue\n            \n            last_token = np.array(seq[-1].item()).reshape(1,)\n            x = torch.tensor(last_token).to(device)\n            \n            if cell_type == 'LSTM':\n                output, hidden, cell, _ = model.decoder(x, encoder_outputs, hidden.squeeze(0), cell)\n            else:\n                output, hidden, _ = model.decoder(x, encoder_outputs, hidden.squeeze(0), None)\n                \n            probabilities = F.softmax(output, dim=1)\n            topk_probs, topk_tokens = torch.topk(probabilities, k=beam_width)\n\n            for prob, token in zip(topk_probs[0], topk_tokens[0]):\n                new_seq = torch.cat((seq, token.unsqueeze(0)), dim=0)\n                seq_length_norm_factor = (len(new_seq) - 1) / 5\n                candidate_score = score + torch.log(prob).item() / (seq_length_norm_factor ** length_penalty)\n                candidates.append((candidate_score, new_seq, hidden.unsqueeze(0)))\n\n        # Select top-k candidates based on the accumulated scores\n        beam = heapq.nlargest(beam_width, candidates, key=lambda x: x[0])\n\n    best_score, best_sequence, _ = max(beam, key=lambda x: x[0])  # Select the best sequence from the beam as the output\n\n    # Convert the best sequence indices to characters\n    return ''.join([reverse_target_char_index[token.item()] for token in best_sequence[1:]])\n\n\n# TRAINING FUNCTION\ndef train(model, num_epochs, criterion, optimizer, train_batch_x, train_batch_y, val_batch_x, val_batch_y, df_val, input_char_to_int, output_char_to_int, output_int_to_char, beam_width, length_penalty, cell_type, max_length):\n    for epoch in range(num_epochs):\n        total_words = 0\n        correct_pred = 0\n        total_loss = 0\n        accuracy = 0\n        model.train()\n        \n        # Use tqdm for progress tracking\n        train_data_iterator = tqdm(zip(train_batch_x, train_batch_y), total=len(train_batch_x))\n        \n        for (x, y) in train_data_iterator:\n            # Get input and targets and move to device\n            target, inp_data = y.to(device), x.to(device)\n            \n            # Forward propagation\n            optimizer.zero_grad()\n            output = model(inp_data, target)\n            \n            target = target.reshape(-1)\n            output = output.reshape(-1, output.shape[2])\n            \n            pad_mask = (target != 0)  \n            target = target[pad_mask] # Select non-padding elements\n            output = output[pad_mask] \n            \n            # Calculate loss\n            loss = criterion(output, target)\n            \n            # Backpropagation\n            loss.backward()\n            \n            # Clip gradients to avoid exploding gradients\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n            \n            # Update parameters\n            optimizer.step()\n            \n            # Accumulate total loss\n            total_loss += loss.item()\n            # Update total words processed\n            total_words += target.size(0)\n            # Calculate number of correct predictions\n            correct_pred += torch.sum(torch.argmax(output, dim=1) == target).item()\n            \n        # Calculate average loss per batch\n        avg_loss = total_loss / len(train_batch_x)\n        # Calculate accuracy\n        accuracy = 100*correct_pred / total_words\n        \n        \n        # Validation\n        model.eval()\n        with torch.no_grad():\n            val_total_loss = 0\n            val_total_words = 0\n            val_correct_pred = 0\n\n            val_data_iterator = tqdm(zip(val_batch_x, val_batch_y), total=len(val_batch_x))\n            for x_val, y_val in val_data_iterator:\n                target_val, inp_data_val = y_val.to(device), x_val.to(device)\n                output_val = model(inp_data_val, target_val)\n                \n                \n                target_val = target_val.reshape(-1)\n                output_val = output_val.reshape(-1, output_val.shape[2])\n                \n                pad_mask = (target_val != 0)  \n                target_val = target_val[pad_mask] # Select non-padding elements\n                output_val = output_val[pad_mask] \n            \n                val_loss = criterion(output_val, target_val)\n                val_total_loss += val_loss.item()\n                val_total_words += target_val.size(0)\n                val_correct_pred += torch.sum(torch.argmax(output_val, dim=1) == target_val).item()\n\n            # Calculate validation statistics\n            val_accuracy = 100*val_correct_pred / val_total_words\n            val_avg_loss = val_total_loss / len(val_batch_x)\n\n            \n        # Total word predict correct over training\n        beam_val_pred = 0\n        beam_val = 0\n        for i in tqdm(range(df_val.shape[0])):\n            input_seq = df_val.iloc[i, 0][:-1] \n            true_seq = df_val.iloc[i, 1][1:-1]\n            predicted_output = beam_search(model, input_seq, max_length, input_char_to_int, output_char_to_int, output_int_to_char, beam_width, length_penalty, cell_type)\n            if true_seq == predicted_output[:-1]:\n                beam_val_pred+=1\n        beam_val = 100*beam_val_pred/df_val.shape[0]\n        \n        # Print statistics\n        print(f\"Epoch {epoch + 1} / {num_epochs} ===========================>\")\n        print(f\"Train Accuracy Char: {accuracy:.4f}, Train Average Loss: {avg_loss:.4f}\")\n        print(f\"Validation Accuracy Char: {val_accuracy:.4f}, Validation Average Loss: {val_avg_loss:.4f}\")\n        print(f\"Beam Val Word Accuracy: {beam_val:.4f} Correct Prediction : {beam_val_pred}/{df_val.shape[0]}\")    \n        # wandb.log({\n        #         \"train_accuracy_char\": accuracy,\n        #         \"train_loss\": avg_loss,\n        #         \"val_accuracy_char\": val_accuracy,\n        #         \"val_loss\": val_avg_loss,\n        #         \"beam_val_accuracy_word\" : beam_val,\n        #     })\n        \n    return model, beam_val","metadata":{"execution":{"iopub.status.busy":"2025-05-20T13:11:51.658432Z","iopub.execute_input":"2025-05-20T13:11:51.658891Z","iopub.status.idle":"2025-05-20T13:11:51.676730Z","shell.execute_reply.started":"2025-05-20T13:11:51.658867Z","shell.execute_reply":"2025-05-20T13:11:51.675999Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## SWEEP RUN","metadata":{}},{"cell_type":"code","source":"def main():\n    wandb.init(project='DA6401_A3_partB')\n    config = wandb.config\n    wandb.run.name = 'attention'+ '_cell_' + config.cell_type + '_bs_' + str(config.batch_size) + '_ep_' + str(config.num_epochs) + '_op_' + str(config.optimizer) + '_drop_' + str(config.dropout) + '_bsw_' + str(config.beam_search_width) +'_emb_' + str(config.embedding_size) + '_hs_' + str(config.hidden_size) + '_elayer_' + str(config.num_layers) + '_dlayer_' + str(config.num_layers)\n    \n    # Load Dataset\n    df_train, train_input_len, train_out_len = load_dataset('/kaggle/input/dakshina/hi.translit.sampled.train.tsv')\n    df_val, val_input_len, val_out_len = load_dataset('/kaggle/input/dakshina/hi.translit.sampled.dev.tsv')\n    df_test, test_input_len, test_out_len = load_dataset('/kaggle/input/dakshina/hi.translit.sampled.test.tsv')\n\n    input_max_len = max(train_input_len, val_input_len, test_input_len)\n    output_max_len = max(train_out_len, val_out_len, test_out_len)\n    \n    max_length = max(input_max_len, output_max_len)\n\n    # Create Look Up Table\n    input_char_to_int, input_int_to_char = look_up_table(df_train[0], df_val[0], df_test[0])\n    output_char_to_int, output_int_to_char = look_up_table(df_train[1], df_val[1], df_test[1])\n\n    # Data Embedding and Converting them into Tensor\n    train_inputs, train_outputs = get_tensor_object(df_train, max_length, max_length, input_char_to_int, output_char_to_int)\n    val_inputs, val_outputs = get_tensor_object(df_val, max_length, max_length, input_char_to_int, output_char_to_int)\n    test_inputs, test_outputs = get_tensor_object(df_test, max_length, max_length, input_char_to_int, output_char_to_int)\n\n    # Transpose column wise\n    train_inputs, train_outputs = torch.transpose(train_inputs, 0, 1), torch.transpose(train_outputs, 0, 1)\n    val_inputs, val_outputs = torch.transpose(val_inputs, 0, 1), torch.transpose(val_outputs, 0, 1)\n    test_inputs, test_outputs = torch.transpose(test_inputs, 0, 1), torch.transpose(test_outputs, 0, 1)\n\n\n    # Initialize Hyperparameters\n    input_size = len(input_char_to_int)\n    output_size = len(output_char_to_int)\n    embedding_size = config.embedding_size\n    hidden_size = config.hidden_size\n    enc_num_layers = config.num_layers\n    dec_num_layers = config.num_layers\n    cell_type = config.cell_type\n    dropout = config.dropout\n    learning_rate = config.learning_rate\n    batch_size = config.batch_size\n    num_epochs = config.num_epochs  \n    optimizer = config.optimizer  \n    beam_width = config.beam_search_width\n    bidirectional = config.bidirectional\n    length_penalty = config.length_penalty\n    teacher_forcing = config.teacher_forcing\n    learning_rate = config.learning_rate\n\n    # Create train data batch\n    train_batch_x, train_batch_y = torch.split(train_inputs, batch_size, dim=1), torch.split(train_outputs, batch_size, dim=1)\n    # Validation data batch\n    val_batch_x, val_batch_y = torch.split(val_inputs, batch_size, dim=1), torch.split(val_outputs, batch_size, dim=1)\n\n\n    # Intialize encoder, decoder and seq2seq model\n    encoder = Encoder(input_size, embedding_size, hidden_size, enc_num_layers, dropout, bidirectional, cell_type).to(device)\n    decoder = Decoder(output_size, embedding_size, hidden_size, output_size, dec_num_layers, dropout, bidirectional, cell_type).to(device)  \n    model = Seq2Seq(encoder, decoder, output_char_to_int, teacher_forcing, cell_type).to(device)\n\n    # Print total number of parameters in the model\n    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(model)\n    print(f'Total Trainable Parameters: {total_params}')\n\n\n    # Loss function and Optimizer\n    criterion = nn.CrossEntropyLoss()\n    if optimizer == 'adam':\n        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    elif optimizer == 'sgd':\n        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n    elif optimizer == 'rmsprop':\n        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n    elif optimizer == 'nadam':\n        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    elif optimizer == 'adagrad':\n        optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)\n    else:\n        print(\"Incorrect Optmizer !!!!\")\n\n    # TRAINING\n    model, acc = train(model, num_epochs, criterion, optimizer, train_batch_x, train_batch_y, val_batch_x, val_batch_y, df_val, input_char_to_int, output_char_to_int, output_int_to_char, beam_width, length_penalty, cell_type, max_length)\n    wandb.log({\n            \"accuracy\": acc,\n        })\n    \n# SWEEP CONFIG\n# sweep_config = {\n#     'name': 'sweep_1_attention',\n#     'method': 'bayes',  \n#     'metric': {'name': 'accuracy', 'goal': 'maximize'},\n#     'parameters': {\n#         'embedding_size': {'values': [256,512]},  \n#         'hidden_size': {'values': [512, 1024]},\n#         'num_layers': {'values': [2]},  \n#         'cell_type': {'values':['LSTM', 'GRU']}, # RNN, LSTM, GRU\n#         'dropout': {'values': [0.3,0.5]},\n#         'learning_rate': {'values': [0.01,0.005]},\n#         'batch_size': {'values': [32,64,128]},\n#         'num_epochs': {'values': [5,10]},\n#         'optimizer': {'values': ['adagrad']}, # ['sgd', 'rmsprop', 'adam', 'nadam']\n#         'beam_search_width': {'values': [1, 4]},\n#         'length_penalty' : {'values': [0.6]},\n#         'bidirectional': {'values': [True]},\n#         'teacher_forcing': {'values': [0.7]}\n#     }\n# }\nsweep_config = {\n    'name': 'sweep_2_attention',\n    'method': 'bayes',  \n    'metric': {'name': 'accuracy', 'goal': 'maximize'},\n    'parameters': {\n        'embedding_size': {'values': [256]},  \n        'hidden_size': {'values': [1024]},\n        'num_layers': {'values': [3]},  \n        'cell_type': {'values':['LSTM']}, # RNN, LSTM, GRU\n        'dropout': {'values': [0.5]},\n        'learning_rate': {'values': [0.0001]},\n        'batch_size': {'values': [64]},\n        'num_epochs': {'values': [10]},\n        'optimizer': {'values': ['adagrad']}, # ['sgd', 'rmsprop', 'adam', 'nadam']\n        'beam_search_width': {'values': [1]},\n        'length_penalty' : {'values': [0.6]},\n        'bidirectional': {'values': [True]},\n        'teacher_forcing': {'values': [0.7]}\n    }\n}\n\n# RUN SWEEP ID with agent\nsweep_id = wandb.sweep(sweep_config, project = 'DA6401_A3_partB')\nwandb.agent(sweep_id, main, count=1)\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2025-05-20T10:24:08.729473Z","iopub.execute_input":"2025-05-20T10:24:08.729780Z","iopub.status.idle":"2025-05-20T10:54:29.577697Z","shell.execute_reply.started":"2025-05-20T10:24:08.729757Z","shell.execute_reply":"2025-05-20T10:54:29.577072Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Create sweep with ID: lxfhbsbz\nSweep URL: https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB/sweeps/lxfhbsbz\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m7g7iw71 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_search_width: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlength_penalty: 0.6\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adagrad\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing: 0.7\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DA6401_A3_partB' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_102416-m7g7iw71</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB/runs/m7g7iw71' target=\"_blank\">ruby-sweep-1</a></strong> to <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB/sweeps/lxfhbsbz' target=\"_blank\">https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB/sweeps/lxfhbsbz</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB' target=\"_blank\">https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB/sweeps/lxfhbsbz' target=\"_blank\">https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB/sweeps/lxfhbsbz</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB/runs/m7g7iw71' target=\"_blank\">https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB/runs/m7g7iw71</a>"},"metadata":{}},{"name":"stdout","text":"Seq2Seq(\n  (decoder): Decoder(\n    (dropout): Dropout(p=0.5, inplace=False)\n    (embedding): Embedding(29, 256)\n    (rnn): LSTM(256, 1024, num_layers=3, dropout=0.5)\n    (concat): Linear(in_features=2048, out_features=1024, bias=True)\n    (fc): Linear(in_features=1024, out_features=29, bias=True)\n    (attn): Attention()\n    (log_softmax): LogSoftmax(dim=1)\n  )\n  (encoder): Encoder(\n    (dropout): Dropout(p=0.5, inplace=False)\n    (embedding): Embedding(66, 256)\n    (rnn): LSTM(256, 1024, num_layers=3, dropout=0.5, bidirectional=True)\n  )\n)\nTotal Trainable Parameters: 85063453\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 691/691 [01:58<00:00,  5.81it/s]\n100%|██████████| 69/69 [00:03<00:00, 18.22it/s]\n100%|██████████| 4358/4358 [00:56<00:00, 77.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 / 10 ===========================>\nTrain Accuracy Char: 24.8230, Train Average Loss: 2.7159\nValidation Accuracy Char: 20.9743, Validation Average Loss: 2.9415\nBeam Val Word Accuracy: 0.0229 Correct Prediction : 1/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 691/691 [01:59<00:00,  5.78it/s]\n100%|██████████| 69/69 [00:03<00:00, 18.20it/s]\n100%|██████████| 4358/4358 [00:57<00:00, 75.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 / 10 ===========================>\nTrain Accuracy Char: 26.0887, Train Average Loss: 2.6679\nValidation Accuracy Char: 21.6116, Validation Average Loss: 2.9311\nBeam Val Word Accuracy: 0.0229 Correct Prediction : 1/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 691/691 [01:59<00:00,  5.77it/s]\n100%|██████████| 69/69 [00:03<00:00, 18.16it/s]\n100%|██████████| 4358/4358 [00:57<00:00, 75.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 / 10 ===========================>\nTrain Accuracy Char: 26.4399, Train Average Loss: 2.6508\nValidation Accuracy Char: 21.5319, Validation Average Loss: 2.9289\nBeam Val Word Accuracy: 0.0229 Correct Prediction : 1/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 691/691 [01:59<00:00,  5.77it/s]\n100%|██████████| 69/69 [00:03<00:00, 18.05it/s]\n100%|██████████| 4358/4358 [00:55<00:00, 78.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 / 10 ===========================>\nTrain Accuracy Char: 26.9733, Train Average Loss: 2.6290\nValidation Accuracy Char: 20.9127, Validation Average Loss: 2.9994\nBeam Val Word Accuracy: 0.0229 Correct Prediction : 1/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 691/691 [01:59<00:00,  5.77it/s]\n100%|██████████| 69/69 [00:03<00:00, 18.20it/s]\n100%|██████████| 4358/4358 [00:56<00:00, 76.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 / 10 ===========================>\nTrain Accuracy Char: 27.7909, Train Average Loss: 2.6042\nValidation Accuracy Char: 21.2544, Validation Average Loss: 2.9861\nBeam Val Word Accuracy: 0.0229 Correct Prediction : 1/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 691/691 [01:59<00:00,  5.78it/s]\n100%|██████████| 69/69 [00:03<00:00, 18.25it/s]\n100%|██████████| 4358/4358 [00:56<00:00, 76.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 / 10 ===========================>\nTrain Accuracy Char: 28.3179, Train Average Loss: 2.5830\nValidation Accuracy Char: 21.4985, Validation Average Loss: 2.9760\nBeam Val Word Accuracy: 0.0229 Correct Prediction : 1/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 691/691 [01:59<00:00,  5.77it/s]\n100%|██████████| 69/69 [00:03<00:00, 18.27it/s]\n100%|██████████| 4358/4358 [00:57<00:00, 76.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 / 10 ===========================>\nTrain Accuracy Char: 28.7721, Train Average Loss: 2.5644\nValidation Accuracy Char: 21.5345, Validation Average Loss: 2.9747\nBeam Val Word Accuracy: 0.0229 Correct Prediction : 1/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 691/691 [01:59<00:00,  5.78it/s]\n100%|██████████| 69/69 [00:03<00:00, 18.19it/s]\n100%|██████████| 4358/4358 [00:56<00:00, 76.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 / 10 ===========================>\nTrain Accuracy Char: 29.0369, Train Average Loss: 2.5496\nValidation Accuracy Char: 21.4188, Validation Average Loss: 2.9964\nBeam Val Word Accuracy: 0.0229 Correct Prediction : 1/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 691/691 [01:59<00:00,  5.78it/s]\n100%|██████████| 69/69 [00:03<00:00, 18.21it/s]\n100%|██████████| 4358/4358 [00:56<00:00, 76.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 / 10 ===========================>\nTrain Accuracy Char: 29.2947, Train Average Loss: 2.5361\nValidation Accuracy Char: 21.5319, Validation Average Loss: 3.0142\nBeam Val Word Accuracy: 0.0229 Correct Prediction : 1/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 691/691 [01:59<00:00,  5.79it/s]\n100%|██████████| 69/69 [00:03<00:00, 18.04it/s]\n100%|██████████| 4358/4358 [00:57<00:00, 75.63it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 10 / 10 ===========================>\nTrain Accuracy Char: 29.4061, Train Average Loss: 2.5254\nValidation Accuracy Char: 21.5704, Validation Average Loss: 3.0086\nBeam Val Word Accuracy: 0.0229 Correct Prediction : 1/4358\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>beam_val_accuracy_word</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy_char</td><td>▁▃▃▄▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▆▆▅▄▃▂▂▁▁</td></tr><tr><td>val_accuracy_char</td><td>▂█▇▁▄▇▇▆▇█</td></tr><tr><td>val_loss</td><td>▂▁▁▇▆▅▅▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.02295</td></tr><tr><td>beam_val_accuracy_word</td><td>0.02295</td></tr><tr><td>train_accuracy_char</td><td>29.40605</td></tr><tr><td>train_loss</td><td>2.52537</td></tr><tr><td>val_accuracy_char</td><td>21.57044</td></tr><tr><td>val_loss</td><td>3.00856</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">attention_cell_LSTM_bs_64_ep_10_op_adagrad_drop_0.5_bsw_1_emb_256_hs_1024_elayer_3_dlayer_3</strong> at: <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB/runs/m7g7iw71' target=\"_blank\">https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB/runs/m7g7iw71</a><br> View project at: <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB' target=\"_blank\">https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_102416-m7g7iw71/logs</code>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Load Dataset\ndf_train, train_input_len, train_out_len = load_dataset('/kaggle/input/dakshina/hi.translit.sampled.train.tsv')\ndf_val, val_input_len, val_out_len = load_dataset('/kaggle/input/dakshina/hi.translit.sampled.dev.tsv')\ndf_test, test_input_len, test_out_len = load_dataset('/kaggle/input/dakshina/hi.translit.sampled.test.tsv')\n\ninput_max_len = max(train_input_len, val_input_len, test_input_len)\noutput_max_len = max(train_out_len, val_out_len, test_out_len)\n\nmax_length = max(input_max_len, output_max_len)\n\n# Create Look Up Table\ninput_char_to_int, input_int_to_char = look_up_table(df_train[0], df_val[0], df_test[0])\noutput_char_to_int, output_int_to_char = look_up_table(df_train[1], df_val[1], df_test[1])\n\nparams = {\n        \"input_size\": len(input_char_to_int),\n        \"output_size\": len(output_char_to_int),\n        \"embedding_size\": 256,\n        \"hidden_size\": 512,\n        \"enc_num_layers\": 2,\n        \"dec_num_layers\": 2,\n        \"cell_type\": \"LSTM\", # LSTM, GRU, RNN\n        \"dropout\": 0.5,\n        \"learning_rate\": 0.005,\n        \"batch_size\": 32,\n        \"num_epochs\": 10,\n        \"optimizer\": 'adagrad',  # ['sgd', 'rmsprop', 'adam', 'nadam']\n        \"beam_search_width\" : 1,\n        \"length_penalty\" : 0.6,\n        \"bidirectional\": True,\n        \"teacher_forcing\":0.7,\n\n    }\n\n# Data Embedding and Converting them into Tensor\ntrain_inputs, train_outputs = get_tensor_object(df_train, max_length, max_length, input_char_to_int, output_char_to_int)\nval_inputs, val_outputs = get_tensor_object(df_val, max_length, max_length, input_char_to_int, output_char_to_int)\ntest_inputs, test_outputs = get_tensor_object(df_test, max_length, max_length, input_char_to_int, output_char_to_int)\n\n# Transpose column wise\ntrain_inputs, train_outputs = torch.transpose(train_inputs, 0, 1), torch.transpose(train_outputs, 0, 1)\nval_inputs, val_outputs = torch.transpose(val_inputs, 0, 1), torch.transpose(val_outputs, 0, 1)\ntest_inputs, test_outputs = torch.transpose(test_inputs, 0, 1), torch.transpose(test_outputs, 0, 1)\n\n\n# Initialize Hyperparameters\ninput_size = params['input_size']\noutput_size = params['output_size']\nembedding_size = params['embedding_size']\nhidden_size = params['hidden_size']\nenc_num_layers = params['enc_num_layers'] \ndec_num_layers = params['dec_num_layers']  \ncell_type = params['cell_type']\ndropout = params['dropout']\nlearning_rate = params['learning_rate']\nbatch_size = params['batch_size']\nnum_epochs = params['num_epochs']  \noptimizer = params['optimizer']  \nbeam_width = params['beam_search_width']\nbidirectional = params['bidirectional']\nlength_penalty = params['length_penalty']\nteacher_forcing = params['teacher_forcing']\n\n# Create train data batch\ntrain_batch_x, train_batch_y = torch.split(train_inputs, batch_size, dim=1), torch.split(train_outputs, batch_size, dim=1)\n# Validation data batch\nval_batch_x, val_batch_y = torch.split(val_inputs, batch_size, dim=1), torch.split(val_outputs, batch_size, dim=1)\n\n\n# Intialize encoder, decoder and seq2seq model\nencoder = Encoder(input_size, embedding_size, hidden_size, enc_num_layers, dropout, bidirectional, cell_type).to(device)\ndecoder = Decoder(output_size, embedding_size, hidden_size, output_size, dec_num_layers, dropout, bidirectional, cell_type).to(device)  \nmodel = Seq2Seq(encoder, decoder, output_char_to_int, teacher_forcing, cell_type).to(device)\n\n\n\n# Print total number of parameters in the model\ntotal_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(model)\nprint(f'Total Trainable Parameters: {total_params}')\n\n\n# Define your loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\nif optimizer == 'adam':\n    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\nelif optimizer == 'sgd':\n    optimizer = optim.SGD(model.parameters(), lr=params['learning_rate'])\nelif optimizer == 'rmsprop':\n    optimizer = optim.RMSprop(model.parameters(), lr=params['learning_rate'])\nelif optimizer == 'nadam':\n    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\nelif optimizer == 'adagrad':\n    optimizer = optim.Adagrad(model.parameters(), lr=params['learning_rate'])\nelse:\n    print(\"Incorrect Optmizer !!!!\")\n\nmodel, acc = train(model, num_epochs, criterion, optimizer, train_batch_x, train_batch_y, val_batch_x, val_batch_y, df_val, input_char_to_int, output_char_to_int, output_int_to_char, beam_width, length_penalty, cell_type, max_length)\n        ","metadata":{"execution":{"iopub.status.busy":"2025-05-20T13:12:42.023760Z","iopub.execute_input":"2025-05-20T13:12:42.024269Z","iopub.status.idle":"2025-05-20T13:33:41.447825Z","shell.execute_reply.started":"2025-05-20T13:12:42.024239Z","shell.execute_reply":"2025-05-20T13:33:41.447156Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Seq2Seq(\n  (decoder): Decoder(\n    (dropout): Dropout(p=0.5, inplace=False)\n    (embedding): Embedding(29, 256)\n    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n    (concat): Linear(in_features=1024, out_features=512, bias=True)\n    (fc): Linear(in_features=512, out_features=29, bias=True)\n    (attn): Attention()\n    (log_softmax): LogSoftmax(dim=1)\n  )\n  (encoder): Encoder(\n    (dropout): Dropout(p=0.5, inplace=False)\n    (embedding): Embedding(66, 256)\n    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5, bidirectional=True)\n  )\n)\nTotal Trainable Parameters: 13695773\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1382/1382 [01:19<00:00, 17.31it/s]\n100%|██████████| 137/137 [00:02<00:00, 62.62it/s]\n100%|██████████| 4358/4358 [00:42<00:00, 101.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 / 10 ===========================>\nTrain Accuracy Char: 66.1978, Train Average Loss: 1.1868\nValidation Accuracy Char: 71.9649, Validation Average Loss: 0.9753\nBeam Val Word Accuracy: 31.8495 Correct Prediction : 1388/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1382/1382 [01:19<00:00, 17.38it/s]\n100%|██████████| 137/137 [00:02<00:00, 64.59it/s]\n100%|██████████| 4358/4358 [00:43<00:00, 101.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 / 10 ===========================>\nTrain Accuracy Char: 75.2473, Train Average Loss: 0.8577\nValidation Accuracy Char: 75.0071, Validation Average Loss: 0.8582\nBeam Val Word Accuracy: 37.7237 Correct Prediction : 1644/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1382/1382 [01:19<00:00, 17.31it/s]\n100%|██████████| 137/137 [00:02<00:00, 63.07it/s]\n100%|██████████| 4358/4358 [00:43<00:00, 100.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 / 10 ===========================>\nTrain Accuracy Char: 76.2413, Train Average Loss: 0.8130\nValidation Accuracy Char: 75.7728, Validation Average Loss: 0.8232\nBeam Val Word Accuracy: 39.9036 Correct Prediction : 1739/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1382/1382 [01:19<00:00, 17.28it/s]\n100%|██████████| 137/137 [00:02<00:00, 63.95it/s]\n100%|██████████| 4358/4358 [00:43<00:00, 100.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 / 10 ===========================>\nTrain Accuracy Char: 76.7675, Train Average Loss: 0.7888\nValidation Accuracy Char: 76.9162, Validation Average Loss: 0.7781\nBeam Val Word Accuracy: 41.3722 Correct Prediction : 1803/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1382/1382 [01:19<00:00, 17.31it/s]\n100%|██████████| 137/137 [00:02<00:00, 63.94it/s]\n100%|██████████| 4358/4358 [00:43<00:00, 100.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 / 10 ===========================>\nTrain Accuracy Char: 77.2857, Train Average Loss: 0.7694\nValidation Accuracy Char: 76.9881, Validation Average Loss: 0.7757\nBeam Val Word Accuracy: 42.1065 Correct Prediction : 1835/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1382/1382 [01:19<00:00, 17.28it/s]\n100%|██████████| 137/137 [00:02<00:00, 63.97it/s]\n100%|██████████| 4358/4358 [00:43<00:00, 100.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 / 10 ===========================>\nTrain Accuracy Char: 77.7332, Train Average Loss: 0.7516\nValidation Accuracy Char: 77.2065, Validation Average Loss: 0.7728\nBeam Val Word Accuracy: 43.2308 Correct Prediction : 1884/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1382/1382 [01:19<00:00, 17.29it/s]\n100%|██████████| 137/137 [00:02<00:00, 64.67it/s]\n100%|██████████| 4358/4358 [00:43<00:00, 100.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 / 10 ===========================>\nTrain Accuracy Char: 77.8798, Train Average Loss: 0.7432\nValidation Accuracy Char: 77.5868, Validation Average Loss: 0.7553\nBeam Val Word Accuracy: 43.6439 Correct Prediction : 1902/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1382/1382 [01:19<00:00, 17.28it/s]\n100%|██████████| 137/137 [00:02<00:00, 63.38it/s]\n100%|██████████| 4358/4358 [00:43<00:00, 99.83it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 / 10 ===========================>\nTrain Accuracy Char: 78.0374, Train Average Loss: 0.7386\nValidation Accuracy Char: 77.2450, Validation Average Loss: 0.7626\nBeam Val Word Accuracy: 43.8045 Correct Prediction : 1909/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1382/1382 [01:20<00:00, 17.26it/s]\n100%|██████████| 137/137 [00:02<00:00, 63.86it/s]\n100%|██████████| 4358/4358 [00:43<00:00, 99.88it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 / 10 ===========================>\nTrain Accuracy Char: 78.1988, Train Average Loss: 0.7287\nValidation Accuracy Char: 77.5354, Validation Average Loss: 0.7534\nBeam Val Word Accuracy: 44.0340 Correct Prediction : 1919/4358\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1382/1382 [01:20<00:00, 17.25it/s]\n100%|██████████| 137/137 [00:02<00:00, 62.62it/s]\n100%|██████████| 4358/4358 [00:43<00:00, 99.58it/s] ","output_type":"stream"},{"name":"stdout","text":"Epoch 10 / 10 ===========================>\nTrain Accuracy Char: 78.3119, Train Average Loss: 0.7240\nValidation Accuracy Char: 77.4763, Validation Average Loss: 0.7539\nBeam Val Word Accuracy: 44.2864 Correct Prediction : 1930/4358\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Store Prediction result","metadata":{}},{"cell_type":"code","source":"def store_results(data_type, words, translations, predictions, results):\n    \"\"\"\n    This function saves the evaluation results to a CSV file.\n\n    Args:\n        data_type (str): The type of data used for evaluation (e.g., 'val', 'test').\n        words (list): List of source words (without start/end tokens).\n        translations (list): List of reference translations (without start/end tokens).\n        predictions (list): List of predicted translated sequences (without start/end tokens).\n        results (list): List of 'Yes' or 'No' indicating correct/incorrect predictions.\n    \"\"\"\n\n    # Create a dictionary to store the results in a structured format\n    log = {\n        'Word': words,\n        'Translation': translations,\n        'Prediction': predictions,\n        'Result': results  # 'Yes' for correct, 'No' for incorrect\n    }\n    \n    # Construct the file path for the CSV file\n    path = '/kaggle/working/predictions.csv'\n\n    # Create a Pandas DataFrame from the dictionary\n    data_frame = pd.DataFrame(log)\n\n    # Save the DataFrame to a CSV file (header=True includes column names, index=False excludes row index)\n    data_frame.to_csv(path, header=True, index=False)\n    \n    # Log to wandb\n    wandb.init(project='DA6401_A3_partB', name='Prediction_Store')\n\n    wandb.log({'Prediction_table': wandb.Table(dataframe= data_frame)})\n\n    wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2025-05-19T08:11:52.242598Z","iopub.execute_input":"2025-05-19T08:11:52.242946Z","iopub.status.idle":"2025-05-19T08:11:52.249071Z","shell.execute_reply.started":"2025-05-19T08:11:52.242923Z","shell.execute_reply":"2025-05-19T08:11:52.248270Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## TEST ACCURACY","metadata":{}},{"cell_type":"code","source":"\ntest_acc = 0\ncorrect_pred = 0\nwords_test = [] \ntranslations_test = [] \npredictions_test = []\nresults_test = []\n\nfor i in tqdm(range(df_test.shape[0])):\n    input_seq = df_test.iloc[i, 0][:-1] \n    true_seq = df_test.iloc[i, 1][1:-1]\n    predicted_output = beam_search(model, input_seq, max_length, input_char_to_int, output_char_to_int, output_int_to_char, beam_width, length_penalty, cell_type)\n    words_test.append(input_seq)\n    translations_test.append(true_seq)\n    predictions_test.append(predicted_output[:-1])\n    if true_seq == predicted_output[:-1]:\n        correct_pred += 1\n        results_test.append('Yes')\n    else:\n        results_test.append('No')\n\ntest_acc = 100 * correct_pred / df_test.shape[0]   \n\nprint(f'Test Accuracy Word Level: {test_acc}, Correctly Predicted: {correct_pred}')\nwandb.init(project='DA6401_A3_partB', name='bestmodel_test')\n\nwandb.log({ \"val_accuracy_word\" : acc,\n            \"test_accuracy_word\" : test_acc\n            })\n\nwandb.finish()\n# store_results('test', words_test, translations_test, predictions_test, results_test)","metadata":{"execution":{"iopub.status.busy":"2025-05-20T13:39:43.462586Z","iopub.execute_input":"2025-05-20T13:39:43.463156Z","iopub.status.idle":"2025-05-20T13:40:36.157943Z","shell.execute_reply.started":"2025-05-20T13:39:43.463129Z","shell.execute_reply":"2025-05-20T13:40:36.157428Z"},"trusted":true},"outputs":[{"name":"stderr","text":"100%|██████████| 4502/4502 [00:44<00:00, 100.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy Word Level: 42.514438027543314, Correctly Predicted: 1914\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_134028-cgmb3xqh</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB/runs/cgmb3xqh' target=\"_blank\">bestmodel_test</a></strong> to <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB' target=\"_blank\">https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB/runs/cgmb3xqh' target=\"_blank\">https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB/runs/cgmb3xqh</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy_word</td><td>▁</td></tr><tr><td>val_accuracy_word</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy_word</td><td>42.51444</td></tr><tr><td>val_accuracy_word</td><td>44.28637</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">bestmodel_test</strong> at: <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB/runs/cgmb3xqh' target=\"_blank\">https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB/runs/cgmb3xqh</a><br> View project at: <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB' target=\"_blank\">https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A3_partB</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_134028-cgmb3xqh/logs</code>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## HEATMAP","metadata":{}},{"cell_type":"code","source":"def predict(model, input_seq, input_char_index, output_char_index, reverse_target_char_index):\n    model.eval()\n    if len(input_seq) > input_max_len+1:\n        print(\"Input Length is exceeding max length!!!!\")\n        return \"\"\n    \n    # Create np array of zero of length i/p \n    input_data = np.zeros((input_max_len+1, 1), dtype=int) # (N,1)\n    \n    # Encode the input\n    for idx, char in enumerate(input_seq):\n        input_data[idx, 0] = input_char_index[char]\n    input_data[idx+1, 0] = input_char_index[\"$\"]\n    \n    # Convert to tensor\n    input_tensor = torch.tensor(input_data, dtype=torch.int64).to(device) # N,1\n    \n    with torch.no_grad():\n        if cell_type == \"LSTM\":\n            encoder_outputs, hidden_state, cell = model.encoder(input_tensor)\n            hidden_state =  hidden_state[:model.decoder.num_layers]\n            cell =  cell[:model.decoder.num_layers]\n        \n        else:\n            encoder_outputs, hidden_state = model.encoder(input_tensor)\n            hidden_state =  hidden_state[:model.decoder.num_layers]\n    \n    output_text = []\n    output_start_token = output_char_index['^'] # SOS token\n    output_start_token_tensor = torch.tensor([output_start_token]).to(device)\n    \n    attentions = torch.zeros(input_max_len + 1, 1, input_max_len + 1)\n    #decoder_attentions = torch.zeros(29, 29)\n    for i in range(1, len(output_char_index)):\n        if cell_type == \"LSTM\":\n            output, hidden_state, cell, attention = model.decoder(output_start_token_tensor, encoder_outputs, hidden_state, cell)\n        else:\n            output, hidden_state, attention = model.decoder(output_start_token_tensor, encoder_outputs, hidden_state, None)\n        \n        #print(attention)\n        predicted_char = reverse_target_char_index[output.argmax(1).item()]\n        attentions[i] = attention\n        #decoder_attentions[i] = attention.data\n        if predicted_char != '$':\n            output_text.append(predicted_char)\n        else:\n            break\n        output_start_token_tensor = torch.tensor([output.argmax(1)]).to(device)\n\n\n    return ''.join(output_text), attentions[:i + 1]","metadata":{"execution":{"iopub.status.busy":"2025-05-19T07:34:15.022865Z","iopub.execute_input":"2025-05-19T07:34:15.023170Z","iopub.status.idle":"2025-05-19T07:34:15.031637Z","shell.execute_reply.started":"2025-05-19T07:34:15.023147Z","shell.execute_reply":"2025-05-19T07:34:15.030845Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def plot_attention_grid(sentences, translations, attentions, figsize=(15, 15)):\n    fig, axes = plt.subplots(4, 3, figsize=figsize)\n    fig.suptitle('Attention Matrix Grid', fontsize=18, fontweight='bold', y=0.95)\n    for i in range(10):  # Changed to 10 examples\n        sentence = list(sentences[i])\n        translation = list(translations[i])\n        attention = attentions[i][:len(translation), :len(sentence)].squeeze(1).detach().numpy()\n        ax = axes.flat[i]\n        im = ax.matshow(attention, cmap='plasma')  # Using 'plasma' colormap for better visualization\n        ax.set_xticks(np.arange(len(sentence)))\n        ax.set_xticklabels(sentence, size=10, fontweight='bold')  # Bold font for input sequence\n        ax.set_yticks(np.arange(len(translation)))\n        hindi_font = FontProperties(fname='/kaggle/input/hindi-font/TiroDevanagariHindi-Regular.ttf')\n        ax.set_yticklabels(translation, size=10, fontproperties=hindi_font, fontweight='bold')  # Bold font for output sequence\n        ax.set_xlabel('Input Sequence', fontsize=12, fontweight='bold')  # Bold font for axis labels\n        ax.set_ylabel('Output Sequence', fontsize=12, fontweight='bold')  # Bold font for axis labels\n        ax.grid(visible=True)  # Showing grid \n        fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)  # Adding colorbar with adjusted position\n        \n    for ax in axes.flat[10:]:  # Changed to start hiding from the 11th subplot\n        ax.axis('off')      \n    fig.tight_layout(rect=[0, 0, 1, 0.93])  # Adjusting layout to avoid overlap with title\n    wandb.log({\"Attention Images\": wandb.Image(fig)})\n    plt.show()\n\n# Get random samples from the test dataset\nimport random\n\n# Set a random seed for reproducibility (optional)\nrandom.seed(42)\n\n# Get total number of rows in test dataset\ntotal_rows = len(df_test)\n\n# Randomly select 10 indices from the dataset\nrandom_indices = random.sample(range(total_rows), 10)  # Changed from 9 to 10\n\ninputs = []\noutputs = []\nattentions = []\n\n# Use the random indices to fetch data\nfor idx in random_indices:\n    input_seq = df_test.iloc[idx, 0][:-1]  # Extract input sequence from DataFrame\n    output_seq = df_test.iloc[idx, 1][:-1]\n    predicted_output, attention = predict(model, input_seq, input_char_to_int, output_char_to_int, output_int_to_char)\n    attention = attention[:, :, :(len(input_seq))]\n    \n    inputs.append(input_seq)\n    outputs.append(output_seq)\n    attentions.append(attention)\n    print(f\"Processing example {idx+1}/{total_rows}: '{input_seq}' → '{output_seq}'\")\n\n# Initialize wandb and plot the attention grid\nwandb.init(project='DA6401_A3_partB', name='Random_Attention_HeatMap_10')\nplot_attention_grid(inputs, outputs, attentions)\nwandb.finish()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}